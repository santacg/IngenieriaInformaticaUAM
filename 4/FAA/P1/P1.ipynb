{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba092e2b-e50a-42a9-bffc-dd3db7f1c0aa",
   "metadata": {},
   "source": [
    "# Apartado 1 Naive-Bayes propio\n",
    "• Tabla con los resultados de la ejecución para los conjuntos de datos\n",
    "analizados (wdbc y heart). Considerar los dos tipos de particionado. Los\n",
    "resultados se refieren a las tasas de error y deben mostrarse tanto con\n",
    "la corrección de Laplace como sin ella. Se debe incluir tanto el\n",
    "promedio de error como su desviación típica. Es importante mostrar\n",
    "todos los resultados agrupados en una tabla para facilitar su evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6907a8fc-4874-4dd1-bc4d-8df02c7bee5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>Laplace</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>True</td>\n",
       "      <td>0.067606</td>\n",
       "      <td>0.014501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>False</td>\n",
       "      <td>0.067606</td>\n",
       "      <td>0.014501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>True</td>\n",
       "      <td>0.070315</td>\n",
       "      <td>0.031910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070315</td>\n",
       "      <td>0.031910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.021050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>False</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.021050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146110</td>\n",
       "      <td>0.053510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>False</td>\n",
       "      <td>0.146110</td>\n",
       "      <td>0.053510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Particionado  Laplace  Error Promedio  Desviación Típica\n",
       "0   wdbc.csv       Simple     True        0.067606           0.014501\n",
       "1   wdbc.csv       Simple    False        0.067606           0.014501\n",
       "2   wdbc.csv      Cruzada     True        0.070315           0.031910\n",
       "3   wdbc.csv      Cruzada    False        0.070315           0.031910\n",
       "4  heart.csv       Simple     True        0.146087           0.021050\n",
       "5  heart.csv       Simple    False        0.146087           0.021050\n",
       "6  heart.csv      Cruzada     True        0.146110           0.053510\n",
       "7  heart.csv      Cruzada    False        0.146110           0.053510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import EstrategiaParticionado\n",
    "from Datos import Datos\n",
    "from Clasificador import ClasificadorNaiveBayes\n",
    "from os import listdir\n",
    "\n",
    "resultados_nb_propio = []\n",
    "# Damos un valor aleatorio a la semilla para cada ejecución\n",
    "seed = random.random()\n",
    "\n",
    "# Ejecutamos cada dataset que se encuentre en la carpeta Datasets\n",
    "for archivo in listdir('Datasets/'):\n",
    "    dataset = Datos('Datasets/' + archivo)\n",
    "    \n",
    "    # Parámetros de las estrategias de particionado\n",
    "    n_ejecuciones = 5\n",
    "    n_folds = 5\n",
    "    estrategia_simple = EstrategiaParticionado.ValidacionSimple(n_ejecuciones, 0.25)\n",
    "    estrategia_cruzada = EstrategiaParticionado.ValidacionCruzada(n_folds)\n",
    "    nb_simple_laplace = ClasificadorNaiveBayes(laplace=1)\n",
    "    nb_cruzada_laplace = ClasificadorNaiveBayes(laplace=1)\n",
    "\n",
    "    # Con corrección de Laplace\n",
    "    error_simple_laplace = nb_simple_laplace.validacion(estrategia_simple, dataset, nb_simple_laplace, seed)\n",
    "    error_cruzada_laplace = nb_cruzada_laplace.validacion(estrategia_cruzada, dataset, nb_cruzada_laplace)\n",
    "    \n",
    "    # Sin corrección de Laplace\n",
    "    nb_simple = ClasificadorNaiveBayes(laplace=0)\n",
    "    nb_cruzada = ClasificadorNaiveBayes(laplace=0)\n",
    "    error_simple = nb_simple.validacion(estrategia_simple, dataset, nb_simple, seed)\n",
    "    error_cruzada = nb_cruzada.validacion(estrategia_cruzada, dataset, nb_cruzada)\n",
    "    \n",
    "    # Calculamos los promedios y las desviaciones típicas y las almacenamos en los resutlados \n",
    "    # para posteriormente mostrarlos en una tabla\n",
    "    resultados_nb_propio.append({\n",
    "        'Dataset': archivo,\n",
    "        'Particionado': 'Simple',\n",
    "        'Laplace': True,\n",
    "        'Error Promedio': np.mean(error_simple_laplace),\n",
    "        'Desviación Típica': np.std(error_simple_laplace)\n",
    "    })\n",
    "    resultados_nb_propio.append({\n",
    "        'Dataset': archivo,\n",
    "        'Particionado': 'Simple',\n",
    "        'Laplace': False,\n",
    "        'Error Promedio': np.mean(error_simple),\n",
    "        'Desviación Típica': np.std(error_simple)\n",
    "    })\n",
    "    resultados_nb_propio.append({\n",
    "        'Dataset': archivo,\n",
    "        'Particionado': 'Cruzada',\n",
    "        'Laplace': True,\n",
    "        'Error Promedio': np.mean(error_cruzada_laplace),\n",
    "        'Desviación Típica': np.std(error_cruzada_laplace)\n",
    "    })\n",
    "    resultados_nb_propio.append({\n",
    "        'Dataset': archivo,\n",
    "        'Particionado': 'Cruzada',\n",
    "        'Laplace': False,\n",
    "        'Error Promedio': np.mean(error_cruzada),\n",
    "        'Desviación Típica': np.std(error_cruzada)\n",
    "    })\n",
    "\n",
    "# Convertimos los resultados en un dataframe\n",
    "df_resultados_nb_propio = pd.DataFrame(resultados_nb_propio)\n",
    "\n",
    "# Mostramos la tabla\n",
    "display(df_resultados_nb_propio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bca0cb-fce6-458a-b701-64ff8a0305a4",
   "metadata": {},
   "source": [
    "• Breve análisis de los resultados anteriores. Discutir el efecto Laplace.\n",
    "\n",
    "Para la creación de particiones se han empleado parámetros estándar que son los que se encuentran por defecto en las versiones correspondientes de scikit learn, en concreto,\n",
    "para la validación simple se ha utilizado un porcentaje del 75% (1 - 0.25) para el tamaño de la partición de entrenamiento y para la validación cruzada se han utilizado 5 folds.\n",
    "\n",
    "Atendiendo a los resultados del conjunto de datos \"wdbc.csv\" podemos ver que tanto el error promedio como la desviación típica son muy bajos, indicando que la clasificación es muy buena teniendo una tasa de error promedio cercana al 5-7%, esto puede deberse a que los datos continuos siguen realmente una distribución Gaussiana y por lo tanto al suponer nuestro Naive Bayes una distribución Gaussiana para estos datos se obtiene este error tan bajo. Por otro lado, observamos que la corrección Laplaciana no afecta al resultado, esto se explica por el hecho de que el conjunto de datos unicamente cuenta con atributos continuos, y no aplicamos dicha corrección para atributos continuos. \n",
    "\n",
    "Analizando los resultados del conjunto \"heart.csv\" observamos unos ratios de error ligeramente más elevados que para el otro conjunto, esto posiblemente se pueda explicar por el hecho de que alguno de los atributos no siga una distribución Gaussiana y a la combinación de verosimilitudes de atributos continuos con categóricos, sin embargo, el error sigue siendo relativamente bajo rondando un 15%. En cuanto a Laplace para conjuntos de entrenamiento grandes no se observa ninguna diferencia significativa puesto que no hay datos que falten en el entrenamiento y Laplace no tiene efecto, sin embargo, si reducimos significativamente el tamaño del conjunto de entrenamiento podemos ver una diferencia alrededor del 5% entre aplicar el suavizado o no, siendo el NB con suavizado más preciso, también hay que considerar que esto es dependiente del factor de suavizado que se aplique, de tal manera que si faltan muchos datos se puede aplicar un factor de corrección de Laplace mayor para obtener una representación mayor para los atributos faltantes y por lo tanto una mejor clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e14bd7-0ed8-47aa-8244-afdabf040c20",
   "metadata": {},
   "source": [
    "# Apartado 2 Naive-Bayes Scikit-Learn\n",
    "• Tabla de resultados equivalente a la anterior, pero utilizando los\n",
    "métodos del paquete scikit-learn: MultinomialNB, GaussianNB y\n",
    "CategoricalNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43e9fbf-c331-41ef-b024-435c86659a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>NB</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "      <th>Laplace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.067133</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.129565</td>\n",
       "      <td>0.022238</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Multinomial + Gaussian</td>\n",
       "      <td>0.154783</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.151485</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.151485</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Multinomial + Gaussian</td>\n",
       "      <td>0.174311</td>\n",
       "      <td>0.042348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset Particionado                      NB  Error Promedio  \\\n",
       "0   Datasets/wdbc.csv       Simple                Gaussian        0.067133   \n",
       "1   Datasets/wdbc.csv      Cruzada                Gaussian        0.061481   \n",
       "2  Datasets/heart.csv       Simple  Categorical + Gaussian        0.130435   \n",
       "3  Datasets/heart.csv       Simple  Categorical + Gaussian        0.129565   \n",
       "4  Datasets/heart.csv       Simple  Multinomial + Gaussian        0.154783   \n",
       "5  Datasets/heart.csv      Cruzada  Categorical + Gaussian        0.151485   \n",
       "6  Datasets/heart.csv      Cruzada  Categorical + Gaussian        0.151485   \n",
       "7  Datasets/heart.csv      Cruzada  Multinomial + Gaussian        0.174311   \n",
       "\n",
       "   Desviación Típica Laplace  \n",
       "0           0.023652     NaN  \n",
       "1           0.014586     NaN  \n",
       "2           0.020761    True  \n",
       "3           0.022238   False  \n",
       "4           0.022609     NaN  \n",
       "5           0.034710    True  \n",
       "6           0.034710   False  \n",
       "7           0.042348     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Datos import Datos\n",
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes as nb\n",
    "\n",
    "def validacion_simple(nb, test_x, test_y):\n",
    "    error_promedio = 1 - nb.score(test_x, test_y)\n",
    "    return error_promedio\n",
    "\n",
    "def validacion_cruzada(df, nb, target): \n",
    "    error_promedio = 1 - model_selection.cross_val_score(nb, df, target, cv=5)\n",
    "    return error_promedio\n",
    "\n",
    "resultados_nb_sklearn = []\n",
    "datasets = ['Datasets/wdbc.csv', 'Datasets/heart.csv']\n",
    "\n",
    "for dataset in datasets:\n",
    "    datos = Datos(dataset)\n",
    "    df = datos.datos\n",
    "\n",
    "    # Separamos la columna target\n",
    "    target = df['Class']\n",
    "    df = df.drop('Class', axis=1)\n",
    "    \n",
    "    n_ejecuciones = 5\n",
    "    lista_errores_simple_laplace_cat = []\n",
    "    lista_errores_simple_cat = []\n",
    "    lista_errores_simple_mult = []\n",
    "    lista_errores_simple_gauss = []\n",
    "\n",
    "    if dataset == 'Datasets/wdbc.csv':\n",
    "        # Validación con Naive Bayes Gaussiano\n",
    "        for i in range(n_ejecuciones):\n",
    "            train_X, test_X, train_y, test_y = model_selection.train_test_split(\n",
    "                df, target, test_size=0.25)\n",
    "            \n",
    "            nb_gaussian = nb.GaussianNB()\n",
    "            nb_gaussian.fit(train_X, train_y)\n",
    "            \n",
    "            # Validación Simple\n",
    "            lista_errores_simple_gauss.append(validacion_simple(nb_gaussian, test_X, test_y))\n",
    "            \n",
    "        nb_gaussian = nb.GaussianNB()\n",
    "        error_cruzada_gauss = validacion_cruzada(df, nb_gaussian, target)\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Simple',\n",
    "            'NB': 'Gaussian',\n",
    "            'Error Promedio': np.mean(lista_errores_simple_gauss),\n",
    "            'Desviación Típica': np.std(lista_errores_simple_gauss)\n",
    "        })\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Cruzada',\n",
    "            'NB': 'Gaussian',\n",
    "            'Error Promedio': np.mean(error_cruzada_gauss),\n",
    "            'Desviación Típica': np.std(error_cruzada_gauss)\n",
    "        })\n",
    "    else:\n",
    "        seed = 10\n",
    "\n",
    "        cols_num = []\n",
    "        cols_cat = []\n",
    "        for idx, col in enumerate(df.columns):\n",
    "            if datos.nominalAtributos[idx] is False:\n",
    "                cols_num.append(col)\n",
    "            else:\n",
    "                cols_cat.append(col)\n",
    "        \n",
    "        lista_errores_simple_clg = []\n",
    "        lista_errores_simple_cg = []\n",
    "        lista_errores_simple_mg = []\n",
    "    \n",
    "        for _ in range(n_ejecuciones):\n",
    "            train_X, test_X, train_y, test_y = model_selection.train_test_split(df, target, test_size=0.25)\n",
    "    \n",
    "            # Entrenamos modelos Naive Bayes independientes\n",
    "            nb_gaussian = nb.GaussianNB()\n",
    "            nb_multinomial = nb.MultinomialNB()\n",
    "            nb_categorical_laplace = nb.CategoricalNB()\n",
    "            nb_categorical = nb.CategoricalNB(alpha=0)\n",
    "    \n",
    "            nb_gaussian.fit(train_X[cols_num], train_y)\n",
    "            nb_categorical_laplace.fit(train_X[cols_cat], train_y)\n",
    "            nb_categorical.fit(train_X[cols_cat], train_y)\n",
    "            nb_multinomial.fit(train_X[cols_cat], train_y)\n",
    "    \n",
    "            # Obtenemos probabilidades de clase\n",
    "            gaussian_probas = nb_gaussian.predict_proba(test_X[cols_num])\n",
    "            categorical_laplace_probas = nb_categorical_laplace.predict_proba(test_X[cols_cat])\n",
    "            categorical_probas = nb_categorical.predict_proba(test_X[cols_cat])\n",
    "            multinomial_probas = nb_multinomial.predict_proba(test_X[cols_cat])\n",
    "    \n",
    "            # Combinamos las probabilidades en una nueva matriz de características\n",
    "            clg = np.hstack((categorical_laplace_probas, gaussian_probas))\n",
    "            cg = np.hstack((categorical_probas, gaussian_probas))\n",
    "            mg = np.hstack((multinomial_probas, gaussian_probas))\n",
    "    \n",
    "            # Ajustamos un nuevo modelo Gaussiano sobre las nuevas características combinadas\n",
    "            nb_clg = nb.GaussianNB()\n",
    "            nb_cg = nb.GaussianNB()\n",
    "            nb_mg = nb.GaussianNB()\n",
    "    \n",
    "            nb_clg.fit(clg, test_y)\n",
    "            nb_cg.fit(cg, test_y)\n",
    "            nb_mg.fit(mg, test_y)\n",
    "    \n",
    "            # Validación Simple sobre los modelos combinados\n",
    "            lista_errores_simple_clg.append(validacion_simple(nb_clg, clg, test_y))\n",
    "            lista_errores_simple_cg.append(validacion_simple(nb_cg, cg, test_y))\n",
    "            lista_errores_simple_mg.append(validacion_simple(nb_mg, mg, test_y))\n",
    "\n",
    "        # Validación cruzada para los modelos combinados\n",
    "        nb_gaussian = nb.GaussianNB()\n",
    "        nb_multinomial = nb.MultinomialNB()\n",
    "        nb_categorical_laplace = nb.CategoricalNB()\n",
    "        nb_categorical = nb.CategoricalNB(alpha=0)\n",
    "        \n",
    "        nb_gaussian.fit(train_X[cols_num], train_y)\n",
    "        nb_categorical_laplace.fit(train_X[cols_cat], train_y)\n",
    "        nb_categorical.fit(train_X[cols_cat], train_y)\n",
    "        nb_multinomial.fit(train_X[cols_cat], train_y)\n",
    "        \n",
    "        gaussian_probas = nb_gaussian.predict_proba(df[cols_num])\n",
    "        categorical_probas = nb_categorical.predict_proba(df[cols_cat])\n",
    "        multinomial_probas = nb_multinomial.predict_proba(df[cols_cat])\n",
    "\n",
    "        clg = np.hstack((categorical_probas, gaussian_probas))\n",
    "        cg = np.hstack((categorical_probas, gaussian_probas))\n",
    "        mg = np.hstack((multinomial_probas, gaussian_probas))\n",
    "\n",
    "        error_cruzada_clg = validacion_cruzada(clg, nb.GaussianNB(), target)\n",
    "        error_cruzada_cg = validacion_cruzada(cg, nb.GaussianNB(), target)\n",
    "        error_cruzada_mg = validacion_cruzada(mg, nb.GaussianNB(), target)\n",
    "\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Simple',\n",
    "            'NB': 'Categorical + Gaussian',\n",
    "            'Laplace': True,\n",
    "            'Error Promedio': np.mean(lista_errores_simple_clg),\n",
    "            'Desviación Típica': np.std(lista_errores_simple_clg)\n",
    "        })\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Simple',\n",
    "            'NB': 'Categorical + Gaussian',\n",
    "            'Laplace': False,\n",
    "            'Error Promedio': np.mean(lista_errores_simple_cg),\n",
    "            'Desviación Típica': np.std(lista_errores_simple_cg)\n",
    "        })\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Simple',\n",
    "            'NB': 'Multinomial + Gaussian',\n",
    "            'Error Promedio': np.mean(lista_errores_simple_mg),\n",
    "            'Desviación Típica': np.std(lista_errores_simple_mg)\n",
    "        })\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Cruzada',\n",
    "            'NB': 'Categorical + Gaussian',\n",
    "            'Laplace': True,\n",
    "            'Error Promedio': np.mean(error_cruzada_clg),\n",
    "            'Desviación Típica': np.std(error_cruzada_clg)\n",
    "        })\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Cruzada',\n",
    "            'NB': 'Categorical + Gaussian',\n",
    "            'Laplace': False,\n",
    "            'Error Promedio': np.mean(error_cruzada_cg),\n",
    "            'Desviación Típica': np.std(error_cruzada_cg)\n",
    "        })\n",
    "        resultados_nb_sklearn.append({\n",
    "            'Dataset': dataset,\n",
    "            'Particionado': 'Cruzada',\n",
    "            'NB': 'Multinomial + Gaussian',\n",
    "            'Error Promedio': np.mean(error_cruzada_mg),\n",
    "            'Desviación Típica': np.std(error_cruzada_mg)\n",
    "        })\n",
    "\n",
    "# Convertimos los resultados en un dataframe\n",
    "df_resultados_nb_sklearn = pd.DataFrame(resultados_nb_sklearn)\n",
    "\n",
    "# Mostramos la tabla\n",
    "display(df_resultados_nb_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0930ab5-47c5-4e33-834f-d030c3fbee7e",
   "metadata": {},
   "source": [
    "• ¿Existe algún problema con alguno de estos métodos en alguno de los\n",
    "dos ficheros? En caso afirmativo, ¿en cuál? ¿por qué? ¿cómo podría\n",
    "resolverse?\n",
    "\n",
    "En \"wdbc.csv\" tanto MultinomialNB como CategoricalNB presentan problemas porque el conjunto de datos contiene solo valores numéricos continuos, y estos modelos están diseñados para tratar unicamente con datos categóricos, con lo cual, la solución adecuada para \"wdbc.csv\" pasa por usar GaussianNB, el cual está diseñado para datos numéricos continuos, o discretizar las variables continuas, en este caso hemos optado por emplear GaussianNB si no existen datos categóricos, como es el caso de dicho conjunto. \n",
    "\n",
    "En \"heart.csv\" hay datos mixtos, es decir, numéricos y categóricos, por ende MultinomialNB y CategoricalNB tendrán problemas para los atributos continuos y GaussianNB para los atributos discretos o categóricos, la solución por la que se ha optado es ajustar de manera independiente un modelo GaussianNB para los atributos continuos y un modelo MultinomialNB o CategoricalNB para los atributos categóricos, luego, se transforman las características del conjunto de datos en probabilidades de asignación de clase y se combinan, permitiendo así que un nuevo modelo GaussianNB que captura la información tanto de las características continuas como categóricas en una representación conjunta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec87b4-67d7-4732-8bd3-73f75f018f55",
   "metadata": {},
   "source": [
    "# Apartado 3 K-NN propio\n",
    "Resultados en forma de tabla de la clasificación mediante\n",
    "vecinos próximos para los diferentes valores de vecindad en\n",
    "los conjuntos de datos propuestos. Obtener los resultados\n",
    "tanto para datos estandarizados como sin estandarizar, con el\n",
    "objetivo de justificar el rendimiento del algoritmo en base a\n",
    "estas características. Separar por tipo de validación (simple,\n",
    "cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc60829-b6d6-44f7-8a86-a38b9ff07162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>K</th>\n",
       "      <th>Normalizado</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.019414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.093122</td>\n",
       "      <td>0.034412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.076056</td>\n",
       "      <td>0.015684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.073793</td>\n",
       "      <td>0.036174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.073239</td>\n",
       "      <td>0.019209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072023</td>\n",
       "      <td>0.045168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.022270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.062478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.014772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042198</td>\n",
       "      <td>0.010327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>0.005270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>0.017171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.029577</td>\n",
       "      <td>0.005270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.043891</td>\n",
       "      <td>0.024778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.010540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.039047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.328696</td>\n",
       "      <td>0.014446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.352964</td>\n",
       "      <td>0.055301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.311304</td>\n",
       "      <td>0.036852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.311671</td>\n",
       "      <td>0.055539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.317391</td>\n",
       "      <td>0.027498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.306207</td>\n",
       "      <td>0.065465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.319130</td>\n",
       "      <td>0.037260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.045840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.193913</td>\n",
       "      <td>0.023750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.197321</td>\n",
       "      <td>0.059267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.018771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.165728</td>\n",
       "      <td>0.058802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.020688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.042864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.157391</td>\n",
       "      <td>0.017260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.159117</td>\n",
       "      <td>0.029140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset Particionado   K  Normalizado  Error Promedio  \\\n",
       "0    Datasets/wdbc.csv       Simple   1        False        0.077465   \n",
       "1    Datasets/wdbc.csv      Cruzada   1        False        0.093122   \n",
       "2    Datasets/wdbc.csv       Simple   5        False        0.076056   \n",
       "3    Datasets/wdbc.csv      Cruzada   5        False        0.073793   \n",
       "4    Datasets/wdbc.csv       Simple  11        False        0.073239   \n",
       "5    Datasets/wdbc.csv      Cruzada  11        False        0.072023   \n",
       "6    Datasets/wdbc.csv       Simple  21        False        0.077465   \n",
       "7    Datasets/wdbc.csv      Cruzada  21        False        0.079025   \n",
       "8    Datasets/wdbc.csv       Simple   1         True        0.042254   \n",
       "9    Datasets/wdbc.csv      Cruzada   1         True        0.042198   \n",
       "10   Datasets/wdbc.csv       Simple   5         True        0.026761   \n",
       "11   Datasets/wdbc.csv      Cruzada   5         True        0.040413   \n",
       "12   Datasets/wdbc.csv       Simple  11         True        0.029577   \n",
       "13   Datasets/wdbc.csv      Cruzada  11         True        0.043891   \n",
       "14   Datasets/wdbc.csv       Simple  21         True        0.039437   \n",
       "15   Datasets/wdbc.csv      Cruzada  21         True        0.049154   \n",
       "16  Datasets/heart.csv       Simple   1        False        0.328696   \n",
       "17  Datasets/heart.csv      Cruzada   1        False        0.352964   \n",
       "18  Datasets/heart.csv       Simple   5        False        0.311304   \n",
       "19  Datasets/heart.csv      Cruzada   5        False        0.311671   \n",
       "20  Datasets/heart.csv       Simple  11        False        0.317391   \n",
       "21  Datasets/heart.csv      Cruzada  11        False        0.306207   \n",
       "22  Datasets/heart.csv       Simple  21        False        0.319130   \n",
       "23  Datasets/heart.csv      Cruzada  21        False        0.297446   \n",
       "24  Datasets/heart.csv       Simple   1         True        0.193913   \n",
       "25  Datasets/heart.csv      Cruzada   1         True        0.197321   \n",
       "26  Datasets/heart.csv       Simple   5         True        0.146087   \n",
       "27  Datasets/heart.csv      Cruzada   5         True        0.165728   \n",
       "28  Datasets/heart.csv       Simple  11         True        0.146087   \n",
       "29  Datasets/heart.csv      Cruzada  11         True        0.164600   \n",
       "30  Datasets/heart.csv       Simple  21         True        0.157391   \n",
       "31  Datasets/heart.csv      Cruzada  21         True        0.159117   \n",
       "\n",
       "    Desviación Típica  \n",
       "0            0.019414  \n",
       "1            0.034412  \n",
       "2            0.015684  \n",
       "3            0.036174  \n",
       "4            0.019209  \n",
       "5            0.045168  \n",
       "6            0.022270  \n",
       "7            0.062478  \n",
       "8            0.014772  \n",
       "9            0.010327  \n",
       "10           0.005270  \n",
       "11           0.017171  \n",
       "12           0.005270  \n",
       "13           0.024778  \n",
       "14           0.010540  \n",
       "15           0.039047  \n",
       "16           0.014446  \n",
       "17           0.055301  \n",
       "18           0.036852  \n",
       "19           0.055539  \n",
       "20           0.027498  \n",
       "21           0.065465  \n",
       "22           0.037260  \n",
       "23           0.045840  \n",
       "24           0.023750  \n",
       "25           0.059267  \n",
       "26           0.018771  \n",
       "27           0.058802  \n",
       "28           0.020688  \n",
       "29           0.042864  \n",
       "30           0.017260  \n",
       "31           0.029140  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Datos import Datos\n",
    "import EstrategiaParticionado\n",
    "from Clasificador import ClasificadorKNN\n",
    "from os import listdir\n",
    "\n",
    "# Valores de K a probar\n",
    "K_values = [1, 5, 11, 21]\n",
    "\n",
    "normalizations = [False, True]\n",
    "\n",
    "# Número de ejecuciones y folds\n",
    "n_ejecuciones = 5\n",
    "n_folds = 5\n",
    "\n",
    "resultados_knn_propio = []\n",
    "datasets = ['Datasets/wdbc.csv', 'Datasets/heart.csv']\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = Datos(dataset)\n",
    "\n",
    "    for normalizado in normalizations:\n",
    "\n",
    "        estrategia_simple = EstrategiaParticionado.ValidacionSimple(\n",
    "            n_ejecuciones, 0.25)\n",
    "        estrategia_cruzada = EstrategiaParticionado.ValidacionCruzada(n_folds)\n",
    "\n",
    "        for K in K_values:\n",
    "            # Validación Simple\n",
    "            neigh_simple = ClasificadorKNN(K=K, normalize=normalizado)\n",
    "            errores_simple = neigh_simple.validacion(\n",
    "                estrategia_simple, df, neigh_simple)\n",
    "\n",
    "            # Validación Cruzada\n",
    "            neigh_cruzada = ClasificadorKNN(K=K, normalize=normalizado)\n",
    "            errores_cruzada = neigh_cruzada.validacion(\n",
    "                estrategia_cruzada, df, neigh_cruzada)\n",
    "\n",
    "            resultados_knn_propio.append({\n",
    "                'Dataset': dataset,\n",
    "                'Particionado': 'Simple',\n",
    "                'K': K,\n",
    "                'Normalizado': normalizado,\n",
    "                'Error Promedio': np.mean(errores_simple),\n",
    "                'Desviación Típica': np.std(errores_simple)\n",
    "            })\n",
    "            resultados_knn_propio.append({\n",
    "                'Dataset': dataset,\n",
    "                'Particionado': 'Cruzada',\n",
    "                'K': K,\n",
    "                'Normalizado': normalizado,\n",
    "                'Error Promedio': np.mean(errores_cruzada),\n",
    "                'Desviación Típica': np.std(errores_cruzada)\n",
    "            })\n",
    "\n",
    "df_resultados_knn_propio = pd.DataFrame(resultados_knn_propio)\n",
    "\n",
    "display(df_resultados_knn_propio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491e75d-89ee-4e2b-93aa-c46e13994fbb",
   "metadata": {},
   "source": [
    "• Análisis de resultados, del impacto de K y de la estandarización\n",
    "\n",
    "¿Qué impacto ha tenido la Normalización?\n",
    "\n",
    "En el primer conjunto de datos, que consta de datos categóricos y numéricos, hemos podido observar una inmensa mejora en elr endimiento tras la aplicación de la estandarización. Sobre todo, podemos ver cómo el error medio disminuye en situaciones en las que el valor de la 'K' es bajo(K=1, K=5). Esta mejora se debe a que al normalizar, todas las características se ajustan a una escala común, además el cálculo de distancias se ve menos afectado por las diferencias de magnitud entre atributos. Para el segundo dataset, compuesto únicamente por datos numéricos continuos, observamos que la aplicación de la normalización provoca una mejor de calidad al evaluar las distancias entre instancias y por tanto, logra una mejora consistente en la precisión para todos los valores de K.\n",
    "\n",
    "Podemos concluir con que la normalización es fundamental para el rendimiento de nuestro modelo, especialmente en datasets con tipos de datos mixtos, como en heart.csv. La normalización nos otorga la capacidad de comparar de manera más justa entre atributos al reducir las diferencias más significantes por la magnitud.\n",
    "\n",
    "¿Qué impacto ha tenido el valor de la K?\n",
    "\n",
    "Para valores pequeños, como K=1 o K=5, observamos que se presenta la mayor cantidad de error en ambos datasets. Esto se debe a que para valores bajos de 'K', el modelo procede a ser más sensible al ruido y a valores atípicos. Con un 'K' pequeño, el modelo es muy sensible a pequeñas variaciones en los datos, ya que un ligero cambio en donde se encuentran los puntos, puede provcar una alteración en el vecino más próximo, cambiando la predicción de clase. En cambio, con valores más altos de K, la decisión se basa en una mayor cantidad de datos, haciendo que el modelo sea menos sensible a pequeñas perturbaciones.\n",
    "\n",
    "¿Qué impacto han tenido los tipos de validaciones?\n",
    "\n",
    "Podemos observar que al aplicar la Validación cruzada, no solo obteníamos una ligera disminución en el error promedio, si no que también obteníamos una desviación típica mucho más alta que en validación simple. La mejora en cuanto al error se debe a que se captura la mejor represnetatividad del modelo, esto es, al promediar el error de múltiples particiones, se obtiene una estimación más precisa del error general del modelo en comparación con la validación simple, ya que se basa en una evaluación sobre múltiples combinaciones de los datos.\n",
    "\n",
    "En cuanto al aumento en la desviación, debido a que el modelo se entrena con un subconjutno de daros ligeramente diferente en cada partición, provocamos que los conjuntos de prueba y entrenamiento estén constantemente cambiando, lo que produce una mayor variabilidad en los resultados de cada partición.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55012888-c131-4d19-b310-1a223e2fc184",
   "metadata": {},
   "source": [
    "# Apartado 4K-NN Scikit-Learn\n",
    "• Tabla de resultados equivalente a la del apartado anterior para las\n",
    "ejecuciones realizadas con la librería KNeighborsClassifier en los\n",
    "mismos valores de K, datos estandarizados y no estandarizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dec92a-6b2a-4e70-b66f-2138e55d04ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>K</th>\n",
       "      <th>Normalizado</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.088112</td>\n",
       "      <td>0.016899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.094892</td>\n",
       "      <td>0.023754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.021936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072054</td>\n",
       "      <td>0.021763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.082517</td>\n",
       "      <td>0.010278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.027740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075524</td>\n",
       "      <td>0.019480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070238</td>\n",
       "      <td>0.034136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.050350</td>\n",
       "      <td>0.012818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049231</td>\n",
       "      <td>0.016353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.008846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>0.009610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>0.011189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.036889</td>\n",
       "      <td>0.020285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.009277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>0.016223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.041155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.372529</td>\n",
       "      <td>0.036769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.296522</td>\n",
       "      <td>0.025412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.336677</td>\n",
       "      <td>0.052590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.016726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.317011</td>\n",
       "      <td>0.066733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.302609</td>\n",
       "      <td>0.030323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315930</td>\n",
       "      <td>0.060135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.189565</td>\n",
       "      <td>0.012481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.202667</td>\n",
       "      <td>0.023156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.119130</td>\n",
       "      <td>0.022775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>0.037770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.147826</td>\n",
       "      <td>0.018446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.188501</td>\n",
       "      <td>0.034498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146957</td>\n",
       "      <td>0.014910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.168888</td>\n",
       "      <td>0.034681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset Particionado   K  Normalizado  Error Promedio  \\\n",
       "0    Datasets/wdbc.csv       Simple   1        False        0.088112   \n",
       "1    Datasets/wdbc.csv      Cruzada   1        False        0.094892   \n",
       "2    Datasets/wdbc.csv       Simple   5        False        0.074126   \n",
       "3    Datasets/wdbc.csv      Cruzada   5        False        0.072054   \n",
       "4    Datasets/wdbc.csv       Simple  11        False        0.082517   \n",
       "5    Datasets/wdbc.csv      Cruzada  11        False        0.070300   \n",
       "6    Datasets/wdbc.csv       Simple  21        False        0.075524   \n",
       "7    Datasets/wdbc.csv      Cruzada  21        False        0.070238   \n",
       "8    Datasets/wdbc.csv       Simple   1         True        0.050350   \n",
       "9    Datasets/wdbc.csv      Cruzada   1         True        0.049231   \n",
       "10   Datasets/wdbc.csv       Simple   5         True        0.027972   \n",
       "11   Datasets/wdbc.csv      Cruzada   5         True        0.035150   \n",
       "12   Datasets/wdbc.csv       Simple  11         True        0.029371   \n",
       "13   Datasets/wdbc.csv      Cruzada  11         True        0.036889   \n",
       "14   Datasets/wdbc.csv       Simple  21         True        0.061538   \n",
       "15   Datasets/wdbc.csv      Cruzada  21         True        0.047431   \n",
       "16  Datasets/heart.csv       Simple   1        False        0.321739   \n",
       "17  Datasets/heart.csv      Cruzada   1        False        0.372529   \n",
       "18  Datasets/heart.csv       Simple   5        False        0.296522   \n",
       "19  Datasets/heart.csv      Cruzada   5        False        0.336677   \n",
       "20  Datasets/heart.csv       Simple  11        False        0.304348   \n",
       "21  Datasets/heart.csv      Cruzada  11        False        0.317011   \n",
       "22  Datasets/heart.csv       Simple  21        False        0.302609   \n",
       "23  Datasets/heart.csv      Cruzada  21        False        0.315930   \n",
       "24  Datasets/heart.csv       Simple   1         True        0.189565   \n",
       "25  Datasets/heart.csv      Cruzada   1         True        0.202667   \n",
       "26  Datasets/heart.csv       Simple   5         True        0.119130   \n",
       "27  Datasets/heart.csv      Cruzada   5         True        0.174353   \n",
       "28  Datasets/heart.csv       Simple  11         True        0.147826   \n",
       "29  Datasets/heart.csv      Cruzada  11         True        0.188501   \n",
       "30  Datasets/heart.csv       Simple  21         True        0.146957   \n",
       "31  Datasets/heart.csv      Cruzada  21         True        0.168888   \n",
       "\n",
       "    Desviación Típica  \n",
       "0            0.016899  \n",
       "1            0.023754  \n",
       "2            0.021936  \n",
       "3            0.021763  \n",
       "4            0.010278  \n",
       "5            0.027740  \n",
       "6            0.019480  \n",
       "7            0.034136  \n",
       "8            0.012818  \n",
       "9            0.016353  \n",
       "10           0.008846  \n",
       "11           0.009610  \n",
       "12           0.011189  \n",
       "13           0.020285  \n",
       "14           0.009277  \n",
       "15           0.016223  \n",
       "16           0.041155  \n",
       "17           0.036769  \n",
       "18           0.025412  \n",
       "19           0.052590  \n",
       "20           0.016726  \n",
       "21           0.066733  \n",
       "22           0.030323  \n",
       "23           0.060135  \n",
       "24           0.012481  \n",
       "25           0.023156  \n",
       "26           0.022775  \n",
       "27           0.037770  \n",
       "28           0.018446  \n",
       "29           0.034498  \n",
       "30           0.014910  \n",
       "31           0.034681  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Datos import Datos\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import neighbors as knn\n",
    "from os import listdir\n",
    "\n",
    "# Valores de K a probar\n",
    "K_values = [1, 5, 11, 21]\n",
    "\n",
    "normalizations = [False, True]\n",
    "\n",
    "# Número de ejecuciones y folds\n",
    "n_ejecuciones = 5\n",
    "\n",
    "resultados_knn_sklearn = []\n",
    "datasets = ['Datasets/wdbc.csv', 'Datasets/heart.csv']\n",
    "\n",
    "for dataset in datasets:\n",
    "    datos = Datos(dataset)\n",
    "    df = datos.datos\n",
    "    # Separamos la columna target\n",
    "    target = df['Class']\n",
    "    df = df.drop('Class', axis=1)\n",
    "    \n",
    "    # Separamos los datos numéricos\n",
    "    datos_numericos = df.select_dtypes(include='number').columns\n",
    "    # Aplicamos la estandarización\n",
    "    dataset_estandarizado = df.copy()\n",
    "    scaler = StandardScaler()\n",
    "    dataset_estandarizado[datos_numericos] = scaler.fit_transform(df[datos_numericos])\n",
    "    \n",
    "    for normalizado in normalizations:\n",
    "        # Usamos los datos estandarizados o sin normalizar según el caso\n",
    "        data = dataset_estandarizado if normalizado else df\n",
    "\n",
    "        for K in K_values:\n",
    "            neigh_simple = knn.KNeighborsClassifier(n_neighbors=K, metric='minkowski', p=2)\n",
    "            neigh_cruzada = knn.KNeighborsClassifier(n_neighbors=K, metric='minkowski', p=2)\n",
    "            knn_error_simple = []\n",
    "            \n",
    "            for _ in range(n_ejecuciones):\n",
    "                # Realizamos la validación simple y el entrenamiento\n",
    "                train_X, test_X, train_y, test_y = model_selection.train_test_split(\n",
    "                    data, target, test_size=0.25)\n",
    "                neigh_simple.fit(train_X, train_y)\n",
    "                knn_error_simple.append(1 - neigh_simple.score(test_X, test_y))\n",
    "\n",
    "            # Validación cruzada\n",
    "            knn_error_cruzada = 1 - model_selection.cross_val_score(neigh_cruzada, data, target, cv=5)\n",
    "            \n",
    "            resultados_knn_sklearn.append({\n",
    "                'Dataset': dataset,\n",
    "                'Particionado': 'Simple',\n",
    "                'K': K,\n",
    "                'Normalizado': normalizado,\n",
    "                'Error Promedio': np.mean(knn_error_simple),\n",
    "                'Desviación Típica': np.std(knn_error_simple)\n",
    "            })\n",
    "            resultados_knn_sklearn.append({\n",
    "                'Dataset': dataset,\n",
    "                'Particionado': 'Cruzada',\n",
    "                'K': K,\n",
    "                'Normalizado': normalizado,\n",
    "                'Error Promedio': np.mean(knn_error_cruzada),\n",
    "                'Desviación Típica': np.std(knn_error_cruzada)\n",
    "            })\n",
    "\n",
    "df_resultados_knn_sklearn = pd.DataFrame(resultados_knn_sklearn)\n",
    "\n",
    "display(df_resultados_knn_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afffdf7-8215-45ca-a053-49325da2f0d9",
   "metadata": {},
   "source": [
    "• Análisis de resultados, del impacto de K y de la estandarización\n",
    "\n",
    "¿Qué impacto ha tenido la Estandarización?\n",
    "\n",
    "En el conjunto de datos que contiene únicamente datos numéricos continuos, observamos una mejora significativa en la precisión del modelo al aplicar la estandarización. Podemos ver la diferencia en valores de 'K' pequeños como 1 y 5, el error promedio disminuye de manera significativa, de aproximadamente 0.08 y 0.05 a valores de 0.04 y 0.03 respectivamente. Esto se debe a que la estandarización ajusta todas las características a una escala común, eliminando los sesgos que podrían haber afectado el cálculo de distancias debido a la magnitud de los valores.\n",
    "\n",
    "En el conjunto de datos mixto, podemos observar una disminución abstante evidente en el error promedio al normalizar los datos. Es decir, para K=1, el error promedio baja de aproximadamente 0.36 a 0.18, mientras que para valores de K más altos como K=11 y K=21, el error disminuye de aproximadamente 0.29 a 0.13. \n",
    "\n",
    "Esta gran diferencia nos indica que la estandarización es enormemente benificiosa para estos tipos de datasets que contienen datos mixtos, ya que permite que el modelo evalúe las distancias de forma equilibrada entre las distintas características.\n",
    "\n",
    "¿Qué impacto ha tenido el valor de la K?\n",
    "\n",
    "Para valores de K pequeños, como K=1 y K=5, observamos un mayor error en ambos conjuntos de datos (wdbc.csv y heart.csv). Esto se debe a que, con valores bajos de K, el modelo es más sensible al ruido y a los valores atípicos. Cuando K es pequeño, el algoritmo se basa en unos pocos vecinos cercanos, lo que puede llevar a errores si esos vecinos son puntos atípicos o de clases minoritarias en la proximidad. En cambio, con valores más altos de K, como K=21, la precisión se estabiliza, especialmente en heart.csv, donde el error promedio baja a aproximadamente 0.13. Esto sugiere que valores de K más altos ayudan a suavizar las predicciones al basarse en un grupo más grande de vecinos, lo que reduce la sensibilidad a pequeñas variaciones en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaecc3c-707f-4603-8415-aa1de08e0ae5",
   "metadata": {},
   "source": [
    "# Apartado 5 Conclusión\n",
    "Comparar y analizar a modo de resumen los resultados propios con\n",
    "los de Scikit-Learn para los dos algoritmos de aprendizaje y ambos\n",
    "conjuntos. Utiliza una tabla para comparar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12633088-564f-43d6-8585-cdc70aed7b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>Laplace</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>True</td>\n",
       "      <td>0.067606</td>\n",
       "      <td>0.014501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>False</td>\n",
       "      <td>0.067606</td>\n",
       "      <td>0.014501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>True</td>\n",
       "      <td>0.070315</td>\n",
       "      <td>0.031910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070315</td>\n",
       "      <td>0.031910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.021050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>False</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.021050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146110</td>\n",
       "      <td>0.053510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>False</td>\n",
       "      <td>0.146110</td>\n",
       "      <td>0.053510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Particionado  Laplace  Error Promedio  Desviación Típica\n",
       "0   wdbc.csv       Simple     True        0.067606           0.014501\n",
       "1   wdbc.csv       Simple    False        0.067606           0.014501\n",
       "2   wdbc.csv      Cruzada     True        0.070315           0.031910\n",
       "3   wdbc.csv      Cruzada    False        0.070315           0.031910\n",
       "4  heart.csv       Simple     True        0.146087           0.021050\n",
       "5  heart.csv       Simple    False        0.146087           0.021050\n",
       "6  heart.csv      Cruzada     True        0.146110           0.053510\n",
       "7  heart.csv      Cruzada    False        0.146110           0.053510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>NB</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "      <th>Laplace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.067133</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.129565</td>\n",
       "      <td>0.022238</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Multinomial + Gaussian</td>\n",
       "      <td>0.154783</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.151485</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Categorical + Gaussian</td>\n",
       "      <td>0.151485</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>Multinomial + Gaussian</td>\n",
       "      <td>0.174311</td>\n",
       "      <td>0.042348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset Particionado                      NB  Error Promedio  \\\n",
       "0   Datasets/wdbc.csv       Simple                Gaussian        0.067133   \n",
       "1   Datasets/wdbc.csv      Cruzada                Gaussian        0.061481   \n",
       "2  Datasets/heart.csv       Simple  Categorical + Gaussian        0.130435   \n",
       "3  Datasets/heart.csv       Simple  Categorical + Gaussian        0.129565   \n",
       "4  Datasets/heart.csv       Simple  Multinomial + Gaussian        0.154783   \n",
       "5  Datasets/heart.csv      Cruzada  Categorical + Gaussian        0.151485   \n",
       "6  Datasets/heart.csv      Cruzada  Categorical + Gaussian        0.151485   \n",
       "7  Datasets/heart.csv      Cruzada  Multinomial + Gaussian        0.174311   \n",
       "\n",
       "   Desviación Típica Laplace  \n",
       "0           0.023652     NaN  \n",
       "1           0.014586     NaN  \n",
       "2           0.020761    True  \n",
       "3           0.022238   False  \n",
       "4           0.022609     NaN  \n",
       "5           0.034710    True  \n",
       "6           0.034710   False  \n",
       "7           0.042348     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_resultados_nb_propio)\n",
    "display(df_resultados_nb_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a7e52-17db-451e-8916-93243aa29cb1",
   "metadata": {},
   "source": [
    "En la comparación entre los resultados propios y los obtenidos con sklearn para el algoritmo Naive Bayes, se observa una consistencia en los errores promedio y la desviación típica en el conjunto \"wdbc.csv\" con un rendimiento casi idéntico en las dos implementaciones, esto tiene sentido ya que en sklearn se emplea el modelo GaussianNB y en nuestra implementación solo se utiliza la distribución gaussiana para calcular la verosimilitud de los datos al no haber datos categóricos, con lo cual en ambas situaciones se emplea la gaussiana de los datos y esto resulta en el rendimiento casi idéntico observado, además la corrección de Laplace no afecta al tratarse de datos continuos. \n",
    "\n",
    "En \"heart.csv\", que incluye datos mixtos, los resultados muestran una ligera ventaja (entre 1% y 2%) en la implementación de sklearn al usar enfoques combinados como Categorical + Gaussian, logrando un error promedio menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a0b664-bfc1-4e2d-bd95-db8c39507fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>K</th>\n",
       "      <th>Normalizado</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.019414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.093122</td>\n",
       "      <td>0.034412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.076056</td>\n",
       "      <td>0.015684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.073793</td>\n",
       "      <td>0.036174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.073239</td>\n",
       "      <td>0.019209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072023</td>\n",
       "      <td>0.045168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.022270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.062478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.014772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042198</td>\n",
       "      <td>0.010327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>0.005270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>0.017171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.029577</td>\n",
       "      <td>0.005270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.043891</td>\n",
       "      <td>0.024778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.010540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.039047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.328696</td>\n",
       "      <td>0.014446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.352964</td>\n",
       "      <td>0.055301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.311304</td>\n",
       "      <td>0.036852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.311671</td>\n",
       "      <td>0.055539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.317391</td>\n",
       "      <td>0.027498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.306207</td>\n",
       "      <td>0.065465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.319130</td>\n",
       "      <td>0.037260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.045840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.193913</td>\n",
       "      <td>0.023750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.197321</td>\n",
       "      <td>0.059267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.018771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.165728</td>\n",
       "      <td>0.058802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.020688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.042864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.157391</td>\n",
       "      <td>0.017260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.159117</td>\n",
       "      <td>0.029140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset Particionado   K  Normalizado  Error Promedio  \\\n",
       "0    Datasets/wdbc.csv       Simple   1        False        0.077465   \n",
       "1    Datasets/wdbc.csv      Cruzada   1        False        0.093122   \n",
       "2    Datasets/wdbc.csv       Simple   5        False        0.076056   \n",
       "3    Datasets/wdbc.csv      Cruzada   5        False        0.073793   \n",
       "4    Datasets/wdbc.csv       Simple  11        False        0.073239   \n",
       "5    Datasets/wdbc.csv      Cruzada  11        False        0.072023   \n",
       "6    Datasets/wdbc.csv       Simple  21        False        0.077465   \n",
       "7    Datasets/wdbc.csv      Cruzada  21        False        0.079025   \n",
       "8    Datasets/wdbc.csv       Simple   1         True        0.042254   \n",
       "9    Datasets/wdbc.csv      Cruzada   1         True        0.042198   \n",
       "10   Datasets/wdbc.csv       Simple   5         True        0.026761   \n",
       "11   Datasets/wdbc.csv      Cruzada   5         True        0.040413   \n",
       "12   Datasets/wdbc.csv       Simple  11         True        0.029577   \n",
       "13   Datasets/wdbc.csv      Cruzada  11         True        0.043891   \n",
       "14   Datasets/wdbc.csv       Simple  21         True        0.039437   \n",
       "15   Datasets/wdbc.csv      Cruzada  21         True        0.049154   \n",
       "16  Datasets/heart.csv       Simple   1        False        0.328696   \n",
       "17  Datasets/heart.csv      Cruzada   1        False        0.352964   \n",
       "18  Datasets/heart.csv       Simple   5        False        0.311304   \n",
       "19  Datasets/heart.csv      Cruzada   5        False        0.311671   \n",
       "20  Datasets/heart.csv       Simple  11        False        0.317391   \n",
       "21  Datasets/heart.csv      Cruzada  11        False        0.306207   \n",
       "22  Datasets/heart.csv       Simple  21        False        0.319130   \n",
       "23  Datasets/heart.csv      Cruzada  21        False        0.297446   \n",
       "24  Datasets/heart.csv       Simple   1         True        0.193913   \n",
       "25  Datasets/heart.csv      Cruzada   1         True        0.197321   \n",
       "26  Datasets/heart.csv       Simple   5         True        0.146087   \n",
       "27  Datasets/heart.csv      Cruzada   5         True        0.165728   \n",
       "28  Datasets/heart.csv       Simple  11         True        0.146087   \n",
       "29  Datasets/heart.csv      Cruzada  11         True        0.164600   \n",
       "30  Datasets/heart.csv       Simple  21         True        0.157391   \n",
       "31  Datasets/heart.csv      Cruzada  21         True        0.159117   \n",
       "\n",
       "    Desviación Típica  \n",
       "0            0.019414  \n",
       "1            0.034412  \n",
       "2            0.015684  \n",
       "3            0.036174  \n",
       "4            0.019209  \n",
       "5            0.045168  \n",
       "6            0.022270  \n",
       "7            0.062478  \n",
       "8            0.014772  \n",
       "9            0.010327  \n",
       "10           0.005270  \n",
       "11           0.017171  \n",
       "12           0.005270  \n",
       "13           0.024778  \n",
       "14           0.010540  \n",
       "15           0.039047  \n",
       "16           0.014446  \n",
       "17           0.055301  \n",
       "18           0.036852  \n",
       "19           0.055539  \n",
       "20           0.027498  \n",
       "21           0.065465  \n",
       "22           0.037260  \n",
       "23           0.045840  \n",
       "24           0.023750  \n",
       "25           0.059267  \n",
       "26           0.018771  \n",
       "27           0.058802  \n",
       "28           0.020688  \n",
       "29           0.042864  \n",
       "30           0.017260  \n",
       "31           0.029140  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Particionado</th>\n",
       "      <th>K</th>\n",
       "      <th>Normalizado</th>\n",
       "      <th>Error Promedio</th>\n",
       "      <th>Desviación Típica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.088112</td>\n",
       "      <td>0.016899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.094892</td>\n",
       "      <td>0.023754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.021936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072054</td>\n",
       "      <td>0.021763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.082517</td>\n",
       "      <td>0.010278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.027740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075524</td>\n",
       "      <td>0.019480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070238</td>\n",
       "      <td>0.034136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.050350</td>\n",
       "      <td>0.012818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049231</td>\n",
       "      <td>0.016353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.008846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>0.009610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>0.011189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.036889</td>\n",
       "      <td>0.020285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.009277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Datasets/wdbc.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>0.016223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.041155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.372529</td>\n",
       "      <td>0.036769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.296522</td>\n",
       "      <td>0.025412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.336677</td>\n",
       "      <td>0.052590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.016726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0.317011</td>\n",
       "      <td>0.066733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.302609</td>\n",
       "      <td>0.030323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315930</td>\n",
       "      <td>0.060135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.189565</td>\n",
       "      <td>0.012481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.202667</td>\n",
       "      <td>0.023156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.119130</td>\n",
       "      <td>0.022775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>0.037770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.147826</td>\n",
       "      <td>0.018446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>0.188501</td>\n",
       "      <td>0.034498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Simple</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.146957</td>\n",
       "      <td>0.014910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Datasets/heart.csv</td>\n",
       "      <td>Cruzada</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.168888</td>\n",
       "      <td>0.034681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset Particionado   K  Normalizado  Error Promedio  \\\n",
       "0    Datasets/wdbc.csv       Simple   1        False        0.088112   \n",
       "1    Datasets/wdbc.csv      Cruzada   1        False        0.094892   \n",
       "2    Datasets/wdbc.csv       Simple   5        False        0.074126   \n",
       "3    Datasets/wdbc.csv      Cruzada   5        False        0.072054   \n",
       "4    Datasets/wdbc.csv       Simple  11        False        0.082517   \n",
       "5    Datasets/wdbc.csv      Cruzada  11        False        0.070300   \n",
       "6    Datasets/wdbc.csv       Simple  21        False        0.075524   \n",
       "7    Datasets/wdbc.csv      Cruzada  21        False        0.070238   \n",
       "8    Datasets/wdbc.csv       Simple   1         True        0.050350   \n",
       "9    Datasets/wdbc.csv      Cruzada   1         True        0.049231   \n",
       "10   Datasets/wdbc.csv       Simple   5         True        0.027972   \n",
       "11   Datasets/wdbc.csv      Cruzada   5         True        0.035150   \n",
       "12   Datasets/wdbc.csv       Simple  11         True        0.029371   \n",
       "13   Datasets/wdbc.csv      Cruzada  11         True        0.036889   \n",
       "14   Datasets/wdbc.csv       Simple  21         True        0.061538   \n",
       "15   Datasets/wdbc.csv      Cruzada  21         True        0.047431   \n",
       "16  Datasets/heart.csv       Simple   1        False        0.321739   \n",
       "17  Datasets/heart.csv      Cruzada   1        False        0.372529   \n",
       "18  Datasets/heart.csv       Simple   5        False        0.296522   \n",
       "19  Datasets/heart.csv      Cruzada   5        False        0.336677   \n",
       "20  Datasets/heart.csv       Simple  11        False        0.304348   \n",
       "21  Datasets/heart.csv      Cruzada  11        False        0.317011   \n",
       "22  Datasets/heart.csv       Simple  21        False        0.302609   \n",
       "23  Datasets/heart.csv      Cruzada  21        False        0.315930   \n",
       "24  Datasets/heart.csv       Simple   1         True        0.189565   \n",
       "25  Datasets/heart.csv      Cruzada   1         True        0.202667   \n",
       "26  Datasets/heart.csv       Simple   5         True        0.119130   \n",
       "27  Datasets/heart.csv      Cruzada   5         True        0.174353   \n",
       "28  Datasets/heart.csv       Simple  11         True        0.147826   \n",
       "29  Datasets/heart.csv      Cruzada  11         True        0.188501   \n",
       "30  Datasets/heart.csv       Simple  21         True        0.146957   \n",
       "31  Datasets/heart.csv      Cruzada  21         True        0.168888   \n",
       "\n",
       "    Desviación Típica  \n",
       "0            0.016899  \n",
       "1            0.023754  \n",
       "2            0.021936  \n",
       "3            0.021763  \n",
       "4            0.010278  \n",
       "5            0.027740  \n",
       "6            0.019480  \n",
       "7            0.034136  \n",
       "8            0.012818  \n",
       "9            0.016353  \n",
       "10           0.008846  \n",
       "11           0.009610  \n",
       "12           0.011189  \n",
       "13           0.020285  \n",
       "14           0.009277  \n",
       "15           0.016223  \n",
       "16           0.041155  \n",
       "17           0.036769  \n",
       "18           0.025412  \n",
       "19           0.052590  \n",
       "20           0.016726  \n",
       "21           0.066733  \n",
       "22           0.030323  \n",
       "23           0.060135  \n",
       "24           0.012481  \n",
       "25           0.023156  \n",
       "26           0.022775  \n",
       "27           0.037770  \n",
       "28           0.018446  \n",
       "29           0.034498  \n",
       "30           0.014910  \n",
       "31           0.034681  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_resultados_knn_propio)\n",
    "display(df_resultados_knn_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116cec42-9da8-462b-a39d-de297c5e3748",
   "metadata": {},
   "source": [
    "En la comparación de los resultados entre la implementación propia de KNN y la de sklearn, se observan diferencias notables en los errores promedio y desviaciones típicas, especialmente en el conjunto \"heart.csv\". En el conjunto \"wdbc.csv\", que contiene datos continuos, ambas implementaciones ofrecen resultados similares sin normalización, aunque la implementación propia muestra una mayor variabilidad (desviación típica más alta) en algunos valores de K, posiblemente debido a diferencias en la gestión de distancias.\n",
    "\n",
    "Con la normalización activada, sklearn y nuestra implementación reducen de forma más consistente el error promedio y la desviación típica en ambos conjuntos, indicando una optimización más robusta en el escalado de los datos. Esto es especialmente evidente en \"heart.csv\", que incluye atributos mixtos. En este conjunto, la implementación propia muestra errores promedio más altos y una mayor variabilidad en particionado cruzado, sugiriendo que sklearn maneja mejor la combinación de atributos de diferentes tipos,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
